{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "In_class_exercise_09.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RkFN0GEa5FL"
      },
      "source": [
        "# **The ninth in-class-exercise (20 points in total, 11/11/2020)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e0wNcNqa5FQ"
      },
      "source": [
        "The purpose of the exercise is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training. \n",
        "\n",
        "The dataset can be download from here: https://github.com/unt-iialab/INFO5731_FALL2020/blob/master/In_class_exercise/exercise09_datacollection.zip. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data. \n",
        "\n",
        "Algorithms:\n",
        "\n",
        "(1) MultinominalNB\n",
        "\n",
        "(2) SVM \n",
        "\n",
        "(3) KNN \n",
        "\n",
        "(4) Decision tree\n",
        "\n",
        "(5) Random Forest\n",
        "\n",
        "(6) XGBoost\n",
        "\n",
        "Evaluation measurement:\n",
        "\n",
        "(1) Accuracy\n",
        "\n",
        "(2) Recall\n",
        "\n",
        "(3) Precison \n",
        "\n",
        "(4) F-1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OANEA60Ka5FS"
      },
      "source": [
        "# Write your code here\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "train=pd.read_csv(\"stsa--train.csv\", encoding=\"cp1252\")\n",
        "train=train [{'1','as quiet,'}]\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn import metrics\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import cross_score\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "test=pd.read_csv(\"stsa-test.csv\",header=None)\n",
        "test=test[{0,1}]\n",
        "A=np.array(train['as quiet,'])\n",
        "testA=np.array(test[1])\n",
        "B=np.array(train['1'])\n",
        "testB=np.array(test[0])\n",
        "trainA, testA, trainB, testB = train_test_split(A, B, size=0.4, random=35)\n",
        "accuracy={}\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiF6MNrecNZM"
      },
      "source": [
        "#support vector machine\n",
        "text_svm = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', LinearSVC())])\n",
        "text_svm.fit(A_train, B_train)\n",
        "predict = text_svm.predict(A_test)\n",
        "scores = cross_score(text_svm, testA, testB, cross=10)\n",
        "print(\"cross_accuracy:\",mean())\n",
        "print(metric_report(B_test, predict))\n",
        "accuracy['svm']=metrics_score(B_test,predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlcTDHyCcRTQ"
      },
      "source": [
        "#k-nearest neighbors\n",
        "text_clf = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', KNeighborsClassifier())])\n",
        "text_clf.fit(A_train, B_train)\n",
        "predict = text_clf.predict(A_test)\n",
        "print(metric_report(B_test, predict))\n",
        "scores = cross_score(text_clf, testA, testB, cv=10)\n",
        "print(\"cross_accuracy:\",mean())\n",
        "accuracy['knn']=metrics_score(B_test,predicted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YQ02COMcUMI"
      },
      "source": [
        "#Random forest\n",
        "text_clf = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', RandomForestClassifier(n_estimators=100))])\n",
        "text_clf.fit(A_train, B_train)\n",
        "predict = text_clf.predict(A_test)\n",
        "print(metric_report(B_test, predicted))\n",
        "scores = cross_score(text_clf, test_A, test_B, cv=10)\n",
        "print(\"cross_accuracy:\",mean())\n",
        "accuracy['forest']=metrics_score(B_test,predict)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}